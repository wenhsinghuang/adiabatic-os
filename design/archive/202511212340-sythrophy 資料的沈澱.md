
資料的沈澱
### Layer 0：Raw / Unstructured Substrate

- 所有外來東西都可以超髒：
    
    - Notion export
        
    - Google Docs / Email / Chat logs
        
    - 任意 JSON / CSV / Markdown
        
- 存成：
    
    - file blob
        
    - `raw_documents(id, mime_type, body BLOB/JSON, ...)`
        
- 這一層可以完全 NoSQL-ish，甚至就是「append-only object store」。
    

### Layer 1：Ephemeral Code Adapters（你說的動態 code）

- Architect / Companion 看到某個需求時：
    
    - 生成一段「從 raw → logical entity」的 adapter：
        
        - `parse_tasks_from_notion_page(raw_md) -> Task[]`
            
        - `infer_mood_from_journal(raw_text) -> MoodLog[]`
            
- 一開始完全 ephemeral、inline 使用，  
    **這正是 AI 寫 code 的強項**：一次性的 parsing / cleaning / inference。
    

### Layer 2：Promoted Structured Views（SQL / Schema）

- 當某個 adapter + entity 被反覆使用，或變成 Auto-Optimize / Context Layer 的基石：
    
    - 把它的結果「落地」成：
        
        - `tasks` 表
            
        - `mood_logs` 表
            
        - `activity_logs` 表
            
- 之後：
    
    - 背景 entropy metrics、dashboard、跨-app 分析 → 全部走 SQL / vec search
        
    - Adapter 只在：
        
        - 更新 raw data 時重跑
            
        - schema 真的改版時更新
            

→ 這樣你其實同時擁有：

- 「底層可以 100% unstructured」這種未來保險
    
- 「上層日常運行全部靠 structured query / vec index」這種效率和穩定度
- 